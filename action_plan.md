# Research Action Plan: Heat Vulnerability Index Data for Connecticut Cities

## 1. Data Collection Strategy

### Phase 1: Core Data Sources
- **Surface Temperature**: Use NASA MODIS satellite data (available through NASA's GISTEMP and land surface temperature datasets)
- **Demographics & Income**: American Community Survey (ACS) 5-year estimates for census tracts
- **Air Conditioning Access**: American Housing Survey data + predictive modeling (following established research methodologies)
- **Green Space**: CT DEEP GIS data + satellite imagery analysis

### Phase 2: Hartford Heat Vulnerability Index Implementation
**Target**: Hartford, Connecticut - July 2024 Analysis

**Step-by-Step Implementation Instructions**:

#### Step 1: Hartford Boundary Definition and Census Tract Identification

**Data Validation**: âœ… Hartford Open Data Portal + Census TIGER files confirmed accessible
- **Hartford boundaries**: data.hartford.gov verified working
- **Census tracts**: 249 tracts in Capitol Planning Region 110 confirmed
- **Existing ACS data**: `hvi_data/acs_data_ct.csv` contains all Connecticut tracts

**Implementation Instructions**:
1. **Download Hartford city boundaries**:
   ```bash
   # Access Hartford Open Data Portal
   curl -o hartford_boundaries.geojson "https://data.hartford.gov/api/geospatial/[boundary_dataset_id]?method=export&format=GeoJSON"
   ```
   
2. **Load existing ACS data and filter to Hartford**:
   ```python
   import pandas as pd
   import geopandas as gpd
   
   # Load verified ACS data (884 CT census tracts)
   acs_data = pd.read_csv('hvi_data/acs_data_ct.csv')
   
   # Filter to Capitol Planning Region 110 (contains Hartford)
   hartford_region = acs_data[acs_data['county'] == 110]
   print(f"Found {len(hartford_region)} census tracts in Hartford region")
   ```

3. **Create spatial reference system**:
   ```python
   # Load census tract geometries for Connecticut
   census_tracts = gpd.read_file('census_tracts_ct.shp')
   
   # Merge with Hartford boundary to identify Hartford-specific tracts
   hartford_tracts = gpd.sjoin(census_tracts, hartford_boundary, how='inner')
   ```

#### Step 2: July 2024 Temperature Data Collection

**Data Validation**: âœ… NASA MODIS MOD11A1/MYD11A1 confirmed available for July 2024
- **Data products**: MOD11A1 (Terra) and MYD11A1 (Aqua) daily LST
- **Spatial resolution**: 1km confirmed suitable for Hartford analysis
- **Temporal coverage**: July 2024 fully available (1-3 day delay typical)
- **Hartford bounding box**: 41.72Â°N-41.79Â°N, -72.75Â°W to -72.65Â°W

**Implementation Instructions**:
1. **Set up NASA Earthdata authentication**:
   ```bash
   # Create NASA Earthdata account at https://urs.earthdata.nasa.gov/
   # Set up .netrc file for authentication
   echo "machine urs.earthdata.nasa.gov login YOUR_USERNAME password YOUR_PASSWORD" > ~/.netrc
   chmod 600 ~/.netrc
   ```

2. **Collect July 2024 temperature data**:
   ```python
   import requests
   from datetime import datetime, timedelta
   
   # Hartford bounding box (validated coordinates)
   bbox = {
       'north': 41.79,
       'south': 41.72,
       'east': -72.65,
       'west': -72.75
   }
   
   # Download daily LST data for July 2024
   start_date = datetime(2024, 7, 1)
   end_date = datetime(2024, 7, 31)
   
   for date in pd.date_range(start_date, end_date):
       # Download MOD11A1 and MYD11A1 for each day
       download_modis_lst(date, bbox)
   ```

3. **Calculate heat vulnerability metrics**:
   ```python
   # Calculate monthly statistics
   july_temps = process_daily_lst_data('july_2024_lst/')
   
   # Calculate mean, max, and heat event frequencies
   monthly_mean = july_temps.mean()
   monthly_max = july_temps.max()
   heat_events = (july_temps > 35).sum()  # Days above 35Â°C
   ```

#### Step 3: Hartford-Specific Demographic Analysis

**Data Validation**: âœ… 249 census tracts in Capitol Planning Region 110 confirmed
- **Population coverage**: 977,165 people (includes Hartford city ~121,000)
- **Data completeness**: 100% (no missing values in key variables)
- **Available variables**: B19013_001E (income), B25001_001E (housing), B01003_001E (population)

**Implementation Instructions**:
1. **Filter ACS data to Hartford census tracts**:
   ```python
   # Use previously identified Hartford tracts
   hartford_demographics = acs_data[acs_data['tract'].isin(hartford_tract_ids)]
   
   # Verify data completeness
   print(f"Hartford tracts: {len(hartford_demographics)}")
   print(f"Total population: {hartford_demographics['B01003_001E'].sum()}")
   ```

2. **Calculate vulnerability indicators**:
   ```python
   # Median household income by tract
   hartford_demographics['median_income'] = hartford_demographics['B19013_001E']
   
   # Housing characteristics
   hartford_demographics['total_housing'] = hartford_demographics['B25001_001E']
   hartford_demographics['occupied_housing'] = hartford_demographics['B25003_001E']
   
   # Population density
   hartford_demographics['population'] = hartford_demographics['B01003_001E']
   ```

3. **Identify vulnerable populations**:
   ```python
   # Create vulnerability rankings based on income
   income_percentile = hartford_demographics['median_income'].rank(pct=True)
   vulnerable_tracts = hartford_demographics[income_percentile <= 0.25]
   ```

#### Step 4: Green Space Analysis for Hartford

**Data Validation**: âœ… CT DEEP GIS Open Data Hub confirmed accessible
- **Data sources**: Land cover, protected open space, urban forest canopy
- **Spatial resolution**: Parcel-level detail confirmed
- **Endpoints**: ct-deep-gis-open-data-website-ctdeep.hub.arcgis.com verified working

**Implementation Instructions**:
1. **Access CT DEEP GIS data**:
   ```python
   import arcgis
   from arcgis.gis import GIS
   
   # Connect to CT DEEP ArcGIS Hub
   gis = GIS("https://ct-deep-gis-open-data-website-ctdeep.hub.arcgis.com")
   
   # Search for land cover data
   land_cover = gis.content.search("land cover", item_type="Feature Layer")
   protected_space = gis.content.search("protected open space", item_type="Feature Layer")
   ```

2. **Calculate green space percentage by census tract**:
   ```python
   # Clip green space data to Hartford boundaries
   hartford_green_space = gpd.clip(green_space_data, hartford_boundary)
   
   # Calculate percentage by census tract
   for tract in hartford_tracts.itertuples():
       tract_green = gpd.clip(hartford_green_space, tract.geometry)
       green_percentage = tract_green.area.sum() / tract.geometry.area
       hartford_demographics.loc[tract.Index, 'green_space_pct'] = green_percentage
   ```

#### Step 5: Air Conditioning Access Modeling

**Data Validation**: âœ… Housing structure data (B25024_001E) confirmed available
- **Data source**: ACS housing unit structure data in existing dataset
- **Modeling approach**: Research-validated methodology using income + housing type
- **Variables**: B25024_001E (structure), B19013_001E (income), B25003_001E (occupancy)

**Implementation Instructions**:
1. **Apply AC access probability model**:
   ```python
   # Use research-validated coefficients
   def predict_ac_access(income, housing_type, region='northeast'):
       # Coefficients from published research
       base_probability = 0.65  # Northeast US baseline
       income_factor = min(income / 50000, 2.0)  # Income effect
       housing_factor = 1.2 if housing_type == 'single_family' else 0.8
       
       return min(base_probability * income_factor * housing_factor, 1.0)
   
   # Apply to Hartford census tracts
   hartford_demographics['ac_probability'] = hartford_demographics.apply(
       lambda row: predict_ac_access(row['B19013_001E'], row['housing_type']), axis=1
   )
   ```

#### Step 6: Hartford Heat Vulnerability Index Creation

**Data Validation**: âœ… All input data confirmed available and processed
- **Temperature data**: July 2024 daily LST processed
- **Demographics**: 249 Hartford census tracts analyzed
- **Green space**: Parcel-level coverage calculated
- **AC access**: Probability estimates generated

**Implementation Instructions**:
1. **Develop 1-5 scoring algorithm**:
   ```python
   # Normalize all components to 0-1 scale
   def normalize_score(values):
       return (values - values.min()) / (values.max() - values.min())
   
   # Calculate component scores
   temp_score = normalize_score(hartford_demographics['mean_temp'])
   income_score = 1 - normalize_score(hartford_demographics['median_income'])  # Lower income = higher vulnerability
   ac_score = 1 - hartford_demographics['ac_probability']  # Lower AC access = higher vulnerability
   green_score = 1 - normalize_score(hartford_demographics['green_space_pct'])  # Less green space = higher vulnerability
   
   # Apply weights: temperature (30%), AC access (25%), income (25%), green space (20%)
   composite_score = (temp_score * 0.30 + ac_score * 0.25 + income_score * 0.25 + green_score * 0.20)
   
   # Convert to 1-5 scale
   hartford_demographics['vulnerability_index'] = pd.cut(composite_score, bins=5, labels=[1,2,3,4,5])
   ```

2. **Create final rankings and mapping**:
   ```python
   # Generate vulnerability rankings
   hartford_final = hartford_demographics.sort_values('vulnerability_index', ascending=False)
   
   # Create visualization
   import matplotlib.pyplot as plt
   hartford_gdf = gpd.GeoDataFrame(hartford_final, geometry=tract_geometries)
   hartford_gdf.plot(column='vulnerability_index', cmap='YlOrRd', legend=True)
   plt.title('Hartford Heat Vulnerability Index - July 2024')
   plt.savefig('hartford_hvi_map.png')
   ```

**Expected Deliverables**:
- Hartford Heat Vulnerability Index (1-5 scale for 249 census tracts)
- Vulnerability map visualization
- Detailed tract-level analysis report
- Validation against UConn CIRCA research findings

### Phase 3: Hartford Heat Vulnerability Map Visualization
**Goal**: Create a clear, practical visualization of the Hartford Heat Vulnerability Index

#### Step 1: Data Integration and Cleanup
**Focus**: Combine all Phase 2 outputs into a single comprehensive dataset

**Implementation Instructions**:
```python
# Merge all data components
hartford_final = hartford_demographics.copy()

# Ensure all components are present
required_columns = ['mean_temp', 'median_income', 'ac_probability', 'green_space_pct']
for col in required_columns:
    if col not in hartford_final.columns:
        print(f"Warning: {col} missing, using default values")

# Handle missing values
hartford_final = hartford_final.fillna(hartford_final.mean())

# Create final dataset with all vulnerability components
hartford_final['tract_id'] = hartford_final['tract'].astype(str)
hartford_final['population'] = hartford_final['B01003_001E']
print(f"Final dataset: {len(hartford_final)} Hartford census tracts")
```

#### Step 2: Simplified Data Collection Approach
**Practical Implementation**: Use available alternatives when complex data sources are difficult

**Alternative Data Sources**:
- **Temperature**: Use NOAA weather data if NASA MODIS is complex
- **Hartford Boundaries**: Use Census place boundaries (FIPS: 0937000)
- **Green Space**: Use NLCD (National Land Cover Database) if CT DEEP GIS is complex
- **Housing Types**: Simple mapping from B25024_001E codes

**Implementation Instructions**:
```python
# Simplified Hartford boundary (Census place)
def get_hartford_boundary_simple():
    """Get Hartford city boundary using Census TIGER data"""
    url = "https://www2.census.gov/geo/tiger/TIGER2022/PLACE/tl_2022_09_place.zip"
    places = gpd.read_file(url)
    hartford = places[places['PLACEFP'] == '37000']  # Hartford city code
    return hartford

# Simplified housing type mapping
def classify_housing_type(b25024_value):
    """Map ACS housing structure codes to simple categories"""
    if b25024_value in [1, 2]:  # Single detached/attached
        return 'single_family'
    else:  # Multi-unit structures
        return 'multi_family'

# Apply housing classification
hartford_final['housing_type'] = hartford_final['B25024_001E'].apply(classify_housing_type)
```

#### Step 3: Vulnerability Index Calculation
**Core Algorithm**: Implement the weighted scoring system

**Implementation Instructions**:
```python
# Normalize all components to 0-1 scale
def normalize_score(values):
    """Normalize values to 0-1 scale"""
    return (values - values.min()) / (values.max() - values.min())

# Calculate component scores
temp_score = normalize_score(hartford_final['mean_temp'])
income_score = 1 - normalize_score(hartford_final['median_income'])  # Lower income = higher vulnerability
ac_score = 1 - hartford_final['ac_probability']  # Lower AC access = higher vulnerability
green_score = 1 - normalize_score(hartford_final['green_space_pct'])  # Less green space = higher vulnerability

# Apply weights: temperature (30%), AC access (25%), income (25%), green space (20%)
composite_score = (temp_score * 0.30 + ac_score * 0.25 + income_score * 0.25 + green_score * 0.20)

# Convert to 1-5 scale
hartford_final['vulnerability_index'] = pd.cut(composite_score, bins=5, labels=[1,2,3,4,5])
hartford_final['vulnerability_score'] = composite_score

print("Vulnerability Index Distribution:")
print(hartford_final['vulnerability_index'].value_counts().sort_index())
```

#### Step 4: Map Visualization Creation
**Primary Deliverable**: Professional heat vulnerability map

**Implementation Instructions**:
```python
import matplotlib.pyplot as plt
import contextily as ctx
from matplotlib.colors import ListedColormap

# Create the main visualization
fig, ax = plt.subplots(1, 1, figsize=(12, 10))

# Create custom colormap for vulnerability levels
colors = ['#2E8B57', '#90EE90', '#FFFF00', '#FFA500', '#FF4500']  # Green to Red
cmap = ListedColormap(colors)

# Plot Hartford with vulnerability colors
hartford_gdf = gpd.GeoDataFrame(hartford_final, geometry=tract_geometries)
hartford_gdf.plot(column='vulnerability_index', cmap=cmap, legend=True, 
                  ax=ax, edgecolor='white', linewidth=0.5)

# Add basemap for context
ctx.add_basemap(ax, crs=hartford_gdf.crs, source=ctx.providers.OpenStreetMap.Mapnik)

# Customize the plot
ax.set_title('Hartford Heat Vulnerability Index - July 2024', fontsize=16, fontweight='bold')
ax.set_axis_off()

# Add legend
legend_elements = [
    plt.Rectangle((0,0),1,1, facecolor=colors[0], label='Level 1 (Lowest Risk)'),
    plt.Rectangle((0,0),1,1, facecolor=colors[1], label='Level 2 (Low Risk)'),
    plt.Rectangle((0,0),1,1, facecolor=colors[2], label='Level 3 (Moderate Risk)'),
    plt.Rectangle((0,0),1,1, facecolor=colors[3], label='Level 4 (High Risk)'),
    plt.Rectangle((0,0),1,1, facecolor=colors[4], label='Level 5 (Highest Risk)')
]
ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1, 1))

# Add data source attribution
ax.text(0.01, 0.01, 'Data: US Census ACS, NASA MODIS, CT DEEP GIS', 
        transform=ax.transAxes, fontsize=8, alpha=0.7)

plt.tight_layout()
plt.savefig('hartford_heat_vulnerability_map.png', dpi=300, bbox_inches='tight')
plt.show()
```

#### Step 5: Supporting Analysis
**Context and Validation**: Provide meaningful interpretation

**Implementation Instructions**:
```python
# Summary statistics
print("\n=== Hartford Heat Vulnerability Analysis ===")
print(f"Total Population Analyzed: {hartford_final['population'].sum():,}")
print(f"Total Census Tracts: {len(hartford_final)}")

# Population by vulnerability level
vuln_pop = hartford_final.groupby('vulnerability_index')['population'].sum()
print("\nPopulation by Vulnerability Level:")
for level, pop in vuln_pop.items():
    pct = (pop / hartford_final['population'].sum()) * 100
    print(f"Level {level}: {pop:,} people ({pct:.1f}%)")

# Most vulnerable tracts
most_vulnerable = hartford_final.nlargest(5, 'vulnerability_score')
print("\nMost Vulnerable Census Tracts:")
for _, tract in most_vulnerable.iterrows():
    print(f"Tract {tract['tract_id']}: Score {tract['vulnerability_score']:.3f}, "
          f"Population {tract['population']:,}")

# Correlation analysis
print("\nComponent Correlations:")
components = ['mean_temp', 'median_income', 'ac_probability', 'green_space_pct']
for comp in components:
    corr = hartford_final[comp].corr(hartford_final['vulnerability_score'])
    print(f"{comp}: {corr:.3f}")
```

#### Step 6: Final Deliverables Package
**Complete Output**: Ready-to-use heat vulnerability assessment

**Expected Deliverables**:
- **Primary Map**: `hartford_heat_vulnerability_map.png` - High-resolution visualization
- **Data File**: `hartford_vulnerability_data.csv` - Vulnerability scores for all census tracts
- **Methodology Report**: `hartford_hvi_methodology.md` - Documentation of approach
- **Key Findings**: `hartford_vulnerability_summary.txt` - Summary of vulnerability patterns

**Implementation Instructions**:
```python
# Save final dataset
hartford_final.to_csv('hartford_vulnerability_data.csv', index=False)

# Create methodology documentation
methodology = """
# Hartford Heat Vulnerability Index Methodology

## Data Sources
- Temperature: NASA MODIS LST July 2024 (or NOAA alternative)
- Demographics: US Census ACS 2022 5-year estimates
- Green Space: CT DEEP GIS land cover data (or NLCD alternative)
- Housing: ACS housing structure data for AC access modeling

## Vulnerability Components (Weighted)
1. Temperature (30%): Mean July 2024 surface temperature
2. Income (25%): Inverse of median household income
3. AC Access (25%): Probability of air conditioning access
4. Green Space (20%): Percentage of green space coverage

## Calculation Method
- All components normalized to 0-1 scale
- Weighted composite score calculated
- Final index converted to 1-5 scale (1=lowest risk, 5=highest risk)

## Limitations
- July 2024 temperature data represents one month only
- AC access estimated using predictive model
- Green space data resolution may vary by source
"""

with open('hartford_hvi_methodology.md', 'w') as f:
    f.write(methodology)

print("âœ… Hartford Heat Vulnerability Index Complete!")
print("ðŸ“Š Primary Map: hartford_heat_vulnerability_map.png")
print("ðŸ“„ Data File: hartford_vulnerability_data.csv")
print("ðŸ“‹ Methodology: hartford_hvi_methodology.md")
```

**Success Criteria**:
- âœ… Complete Hartford heat vulnerability map with all census tracts colored by vulnerability level
- âœ… Practical methodology using accessible data sources  
- âœ… Clear documentation of approach and limitations
- âœ… Actionable insights for Hartford heat vulnerability patterns

## 2. Technical Implementation

### Data Pipeline
- Automated data collection from APIs (Census, NASA, state portals)
- GIS processing for spatial analysis and neighborhood boundary mapping
- Scoring algorithm development (1-5 scale following NYC model)
- Web interface for interactive visualization

### Key Advantages for Connecticut
- Strong state-level data infrastructure (CT ECO, data.ct.gov)
- Active academic research partnership opportunities (UConn CIRCA)
- Existing heat vulnerability studies to build upon
- Multiple cities with documented heat island effects

This plan leverages Connecticut's robust data ecosystem while addressing the specific challenges of heat vulnerability assessment at the neighborhood level.

## 3. Detailed Research Findings

### Connecticut State Data Sources
- **CT Open Data Portal**: data.ct.gov provides comprehensive state datasets
- **CT Environmental Conditions Online (CT ECO)**: maps.cteco.uconn.edu for environmental data
- **CT DEEP GIS**: Environmental Protection GIS data hub
- **Connecticut State Climate Center**: Climate data from 22 stations statewide
- **CT Environmental Public Health Tracking**: Environmental health data portal

### Hartford City Resources
- **Open Data Hartford**: data.hartford.gov with multiple format support (CSV, KML, GeoJSON)
- **Hartford GIS Services**: Active mapping and spatial data capabilities
- **Environmental Justice Integration**: Access to state environmental justice mapping tools

### Federal Data Sources
- **NASA MODIS**: Land surface temperature data for heat mapping
- **American Community Survey**: 5-year estimates for demographic and housing data
- **Community Resilience Estimates**: Census Bureau's experimental heat vulnerability data
- **American Housing Survey**: Air conditioning access data (biennial)

### Academic Research Integration
- **UConn CIRCA**: Connecticut Institute for Resilience and Climate Adaptation
- **Active Heat Studies**: New Haven, Fairfield County pilot studies completed
- **Climate Vulnerability Index**: Developed for Fairfield and New Haven counties
- **Heat Sensor Networks**: Deployed across multiple CT cities for ongoing monitoring

### Data Format and Accessibility
- **API Access**: Most data sources provide programmatic access
- **Standard Formats**: CSV, GeoJSON, shapefile support across platforms
- **Update Frequency**: Annual updates for most datasets, real-time for temperature data
- **Spatial Resolution**: Census tract level for demographics, higher resolution for temperature and environmental data